{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "known-sport",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "from dateutil.tz import tzoffset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from scipy.stats import kendalltau, spearmanr\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-ultimate",
   "metadata": {},
   "source": [
    "# Задача 1\n",
    "\n",
    "Прочитайте и проанализируйте данные, выберите турниры, в которых есть данные о составах команд и повопросных результатах (поле mask в results.pkl). Для унификации предлагаю:\n",
    "- взять в тренировочный набор турниры с dateStart из 2019 года; \n",
    "- в тестовый — турниры с dateStart из 2020 года."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "significant-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"players.pkl\", \"rb\") as fio:\n",
    "    players = pickle.load(fio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sensitive-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.pkl\", \"rb\") as fio:\n",
    "    results = pickle.load(fio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "killing-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tournaments.pkl\", \"rb\") as fio:\n",
    "    tournaments = pickle.load(fio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "threatened-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "dateformat = \"%Y-%m-%dT%H:%M:%S%z\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-folks",
   "metadata": {},
   "source": [
    "Загрузим данные и разделим на тренировочный и тестовый датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-lyric",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data =  []\n",
    "test_data = []\n",
    "\n",
    "for key, value in results.items():\n",
    "    for team in value:\n",
    "        for team_member in team[\"teamMembers\"]:\n",
    "            tournament_year = datetime.strptime(tournaments[key][\"dateStart\"], dateformat).year\n",
    "            if team.get(\"mask\", None) and tournament_year == 2019:\n",
    "                train_data.append({\n",
    "                    \"tournament_id\": key,\n",
    "                    \"tournament_name\": tournaments.get(key).get(\"name\"),\n",
    "                    \"team_id\": team[\"team\"][\"id\"],\n",
    "                    \"team_name\": team[\"team\"][\"name\"],\n",
    "                    \"questions_mask\": team.get(\"mask\", None),\n",
    "                    \"questionQty\": tournaments.get(key).get(\"questionQty\"),\n",
    "                    \"position\": team.get(\"position\", None),\n",
    "                    \"player_id\": team_member[\"player\"][\"id\"],\n",
    "                    \"player_name\": team_member[\"player\"][\"surname\"] + \" \" + \\\n",
    "                                   team_member[\"player\"][\"name\"] + \" \" + \\\n",
    "                                   team_member[\"player\"][\"patronymic\"]\n",
    "                })\n",
    "            elif team.get(\"mask\", None) and tournament_year == 2020:\n",
    "                test_data.append({\n",
    "                    \"tournament_id\": key,\n",
    "                    \"tournament_name\": tournaments.get(key).get(\"name\"),\n",
    "                    \"team_id\": team[\"team\"][\"id\"],\n",
    "                    \"team_name\": team[\"team\"][\"name\"],\n",
    "                    \"position\": team.get(\"position\", None),\n",
    "                    \"player_id\": team_member[\"player\"][\"id\"],\n",
    "                    \"player_name\": team_member[\"player\"][\"surname\"] + \" \" + \\\n",
    "                                   team_member[\"player\"][\"name\"] + \" \" + \\\n",
    "                                   team_member[\"player\"][\"patronymic\"]\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(train_data)\n",
    "test_data = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "del results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-fundamental",
   "metadata": {},
   "source": [
    "оставим только те команды у которых длинна ответов равна количеству вопросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"questionQty\"] = train_data[\"questionQty\"].apply(lambda x: sum(list(x.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[train_data[\"questions_mask\"].apply(len) != train_data[\"questionQty\"]][\"tournament_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[train_data[\"questions_mask\"].apply(len) == train_data[\"questionQty\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-saudi",
   "metadata": {},
   "source": [
    "посмотрим распределение числа игроков по командам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-injection",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(train_data.groupby([\"team_id\", \"tournament_id\"])[\"player_id\"].nunique());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-explosion",
   "metadata": {},
   "source": [
    "посмотрим на итоговый размер данных и количество турниров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape[0], test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"tournament_id\"].nunique(), test_data[\"tournament_id\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-drink",
   "metadata": {},
   "source": [
    "# Задача 2\n",
    "\n",
    "Постройте baseline-модель на основе линейной или логистической регрессии, которая будет обучать рейтинг-лист игроков.\n",
    "\n",
    "- повопросные результаты — это фактически результаты броска монетки, и их предсказание скорее всего имеет отношение к бинарной классификации;\n",
    "- в разных турнирах вопросы совсем разного уровня сложности, поэтому модель должна это учитывать; скорее всего, модель должна будет явно обучать не только силу каждого игрока, но и сложность каждого вопроса;\n",
    "- для baseline-модели можно забыть о командах и считать, что повопросные результаты команды просто относятся к каждому из её игроков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-purpose",
   "metadata": {},
   "source": [
    "Преобразуем тренировочные данные в повопросные результаты по игрокам, в качестве id вопроса будем использовать id турнира и порядковый номер вопроса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-engine",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_data = {\n",
    "    \"question\": [],\n",
    "    \"player\": [],\n",
    "    \"initial_label\": [],\n",
    "    \"team_id\": [],\n",
    "    \"tournament_id\": []\n",
    "}\n",
    "for tour_id, team_id, player_id, mask in zip(train_data[\"tournament_id\"], train_data[\"team_id\"], train_data[\"player_id\"], train_data[\"questions_mask\"]):\n",
    "    for i, result in enumerate(mask):\n",
    "        if result != \"X\" and result != \"?\":\n",
    "            question_answer_data[\"tournament_id\"].append(tour_id)\n",
    "            question_answer_data[\"team_id\"].append(team_id)\n",
    "            question_answer_data[\"question\"].append(f\"{tour_id}_{i}\")\n",
    "            question_answer_data[\"player\"].append(player_id)\n",
    "            question_answer_data[\"initial_label\"].append(int(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-occupation",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_data = pd.DataFrame(question_answer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_data[\"player\"] = question_answer_data[\"player\"].astype(np.int32)\n",
    "question_answer_data[\"team_id\"] = question_answer_data[\"team_id\"].astype(np.int32)\n",
    "question_answer_data[\"tournament_id\"] = question_answer_data[\"tournament_id\"].astype(np.int32)\n",
    "question_answer_data[\"question\"] = question_answer_data[\"question\"]\n",
    "question_answer_data[\"initial_label\"] = question_answer_data[\"initial_label\"].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-annex",
   "metadata": {},
   "source": [
    "закодируем id игроков и вопросов в OHE представление, добавим константу для bias, для удобства"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "\n",
    "train_data = encoder.fit_transform(question_answer_data[[\"player\", \"question\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-title",
   "metadata": {},
   "source": [
    "Введем вспомогательные функции для нашей логистической регрессии\n",
    "\n",
    "- sigmoid - сигмойда над линейной комбинацией признаков и весов\n",
    "- cost_function - среднее логарифмическое правдоподобие\n",
    "- gradient - градиент dL/dw на текущей итерации\n",
    "- fit функция тренировки модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_features):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(n_features, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.fc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_step(model, x, y, lr=1e-4, n_iter=50):\n",
    "    \n",
    "    model.fc.reset_parameters()\n",
    "    criteria = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "    for i in range(n_iter):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criteria(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-punishment",
   "metadata": {},
   "source": [
    "введем функцию которая будет брать топ 20 игроков по силе игрока полученной из модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_players(parameters, n=20):\n",
    "    player_weights = {}\n",
    "    for i, c in enumerate(encoder.get_feature_names()):\n",
    "        if c.startswith(\"x0_\"):\n",
    "            player_weights[int(c[3:])] = parameters[i]\n",
    "    top_players = sorted([(k, v) for k, v in player_weights.items()], reverse=True, key=lambda x: x[1])[:n]\n",
    "    top_players = [\n",
    "        players[i][\"surname\"] + \" \" + \n",
    "        players[i][\"name\"] + \" \" + \n",
    "        players[i][\"patronymic\"] + \" \" + str(i) \n",
    "        for i, _ in top_players\n",
    "    ]\n",
    "    return top_players"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-century",
   "metadata": {},
   "source": [
    "Обучим модель предсказывать ответил ли игрок i на вопрос j\n",
    "\n",
    "Для начала воспользуемся простым предположением - если команда ответила на вопрос то тогда каждый из игроков ответил на вопрос\n",
    "\n",
    "Если команда не ответила на вопрос то каждый из игроков не ответил на него\n",
    "\n",
    "Тогда:\n",
    "\n",
    "$$\\large{\\sigma(p_i + q_j + \\mu) = p(z=1) = p(t=1)}$$\n",
    "\n",
    "Метки для p(t = 1) у нас есть в данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.tocoo()\n",
    "\n",
    "x = torch.sparse.FloatTensor(\n",
    "    torch.LongTensor(np.vstack((train_data.row, train_data.col))),\n",
    "    torch.FloatTensor(train_data.data)\n",
    ")\n",
    "\n",
    "y = torch.FloatTensor(question_answer_data[\"initial_label\"].values).view(-1, 1)\n",
    "\n",
    "model = LogisticRegression(x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "m_step(model, x, y, lr=1, n_iter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-actor",
   "metadata": {},
   "source": [
    "# Задача 3\n",
    "\n",
    "Качество рейтинг-системы оценивается качеством предсказаний результатов турниров. Но сами повопросные результаты наши модели предсказывать вряд ли смогут, ведь неизвестно, насколько сложными окажутся вопросы в будущих турнирах; да и не нужны эти предсказания сами по себе. Поэтому:\n",
    "- предложите способ предсказать результаты нового турнира с известными составами, но неизвестными вопросами, в виде ранжирования команд;\n",
    "- в качестве метрики качества на тестовом наборе давайте считать ранговые корреляции Спирмена и Кендалла (их можно взять в пакете scipy) между реальным ранжированием в результатах турнира и предсказанным моделью, усреднённые по тестовому множеству турниров.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-leisure",
   "metadata": {},
   "source": [
    "функция для подсчета метрик на тестовом датасете\n",
    "\n",
    "силу команды будем трактовать как вероятность того что хотя бы один игрок из команды ответит на средний вопрос\n",
    "\n",
    "$$\\large{team_i = 1 - \\prod_{j = 1}^{N}(1 - \\sigma(p_{ij} + q_{mean} + \\mu))}$$\n",
    "\n",
    "Где:\n",
    "- $p_{ij}$ - сила игрока j в команде i\n",
    "- N - количество игроков в команде i\n",
    "- $q_{mean}$ - средний вопрос\n",
    "- $\\mu$ - глобальная константа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(data, encoder, parameters, intercept):\n",
    "    player_weights = {}\n",
    "    count = 0\n",
    "    question_sum = 0\n",
    "    player_sum = 0\n",
    "    player_cnt = 0\n",
    "    for i, c in enumerate(encoder.get_feature_names()):\n",
    "        if c.startswith(\"x0_\"):\n",
    "            player_weights[int(c[3:])] = parameters[i]\n",
    "            player_sum += parameters[i]\n",
    "            player_cnt += 1\n",
    "        else:\n",
    "            question_sum += parameters[i]\n",
    "            count += 1\n",
    "    question_mean = question_sum / count\n",
    "    data[\"player_weights\"] = data[\"player_id\"].map(player_weights)\n",
    "    data[\"player_weights\"].fillna(player_sum / player_cnt, inplace=True)\n",
    "    data[\"players_proba\"] = data[\"player_weights\"].apply(lambda x: 1 / (1 + np.exp(-(x + question_mean + intercept))))\n",
    "    probas = data.groupby([\"tournament_id\", \"team_id\"])[\"players_proba\"].apply(lambda x: np.prod(1 - x))\n",
    "    position = data.groupby([\"tournament_id\", \"team_id\"])[\"position\"].first()\n",
    "    group_data = pd.concat([probas, position], axis=1)\n",
    "    group_data.sort_values([\"tournament_id\", \"players_proba\"], ascending=[True, True], inplace=True)\n",
    "    spear = group_data.groupby(\"tournament_id\").apply(lambda x: spearmanr(x[\"position\"], x[\"players_proba\"]).correlation).mean()\n",
    "    kendl = group_data.groupby(\"tournament_id\").apply(lambda x: kendalltau(x[\"position\"], x[\"players_proba\"]).correlation).mean()\n",
    "    print(f\"spearman: {spear}\")\n",
    "    print(f\"kendl: {kendl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_metrics(test_data, encoder, model.fc.weight.data[0].numpy(), model.fc.bias.data[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_players(model.fc.weight.data[0].numpy(), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-summit",
   "metadata": {},
   "source": [
    "# Задача 4\n",
    "\n",
    "Теперь главное: ЧГК — это всё-таки командная игра. Поэтому:\n",
    "- предложите способ учитывать то, что на вопрос отвечают сразу несколько игроков; скорее всего, понадобятся скрытые переменные; не стесняйтесь делать упрощающие предположения, но теперь переменные “игрок X ответил на вопрос Y” при условии данных должны стать зависимыми для игроков одной и той же команды;\n",
    "- разработайте EM-схему для обучения этой модели, реализуйте её в коде;\n",
    "- обучите несколько итераций, убедитесь, что целевые метрики со временем растут (скорее всего, ненамного, но расти должны), выберите лучшую модель, используя целевые метрики.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-manor",
   "metadata": {},
   "source": [
    "Воспользуемся простыми предположениями:\n",
    "\n",
    "1. Если один из игроков ответил на вопрос то тогда команда ответила на вопрос\n",
    "2. Если команда не ответила на вопрос, то все игроки не ответили на него\n",
    "3. Игроки отвечают на вопрос независимо\n",
    "\n",
    "Тогда будем моделировать\n",
    "\n",
    "$$\\large{p(z_{ij}=1|t_{i}=y)}$$\n",
    "\n",
    "Очевидно что:\n",
    "\n",
    "$$\\large{p(z_{ij}=1|t_{i}=0) = 0}$$\n",
    "\n",
    "Осталось посчитать:\n",
    "\n",
    "$$\\large{p(z_{ij}=1|t_{i}=1) = \\frac{p(t_{i}=1|z_{ij}=1)p(z_{ij}=1)}{p(t_{i}=1)}}$$\n",
    "\n",
    "- $\\large{p(t=1|z=1) = 1}$ по нашему второму предположению\n",
    "- $\\large{p(z=1) = \\sigma(p_i + q_j + \\mu)}$ - возьмем предсказание из модели полученной на М-шаге\n",
    "- $\\large{p(t_{i}=1) = 1 - \\prod_{k=1}^{N}(1 - \\sigma(p_{ik} + q_j + \\mu))}$ - вероятность команды ответить на вопрос это 1 - вероятность что все игроки не ответили на него\n",
    "\n",
    "Тогда:\n",
    "\n",
    "$$\\large{p(z_{ij}=1|t_{i}=1) = \\frac{\\sigma(p_i + q_j + \\mu)}{1 - \\prod_{k=1}^{N}(1 - \\sigma(p_{ik} + q_j + \\mu))}}$$\n",
    "\n",
    "Это и будет нашим Е-шагом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_step(data, predicts):\n",
    "    data[\"label\"] = predicts\n",
    "    data.loc[data[\"initial_label\"] == 0, \"label\"] = 0\n",
    "    idx = data[\"initial_label\"] == 1\n",
    "    sp = data.loc[idx].groupby([\"team_id\", \"question\"])[\"label\"].transform(lambda x: 1 - np.prod(1 - x.values))\n",
    "    data.loc[idx, \"label\"] = data.loc[idx, \"label\"] / sp  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-instrument",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicts = model(x).detach().numpy().ravel()\n",
    "for i in range(0, 20):\n",
    "    question_answer_data = e_step(question_answer_data, predicts)\n",
    "    y = torch.FloatTensor(question_answer_data[\"label\"].values).view(-1, 1)\n",
    "    m_step(model, x, y, lr=1, n_iter=100)\n",
    "    predicts = model(x).detach().numpy().ravel()\n",
    "    print(f\"Iter: {i}\")\n",
    "    calc_metrics(test_data, encoder, model.fc.weight.data[0].numpy(), model.fc.bias.data[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-eligibility",
   "metadata": {},
   "source": [
    "# Задача 5\n",
    "\n",
    "А что там с вопросами? Постройте “рейтинг-лист” турниров по сложности вопросов. Соответствует ли он интуиции (например, на чемпионате мира в целом должны быть сложные вопросы, а на турнирах для школьников — простые)? Если будет интересно: постройте топ сложных и простых вопросов со ссылками на конкретные записи в базе вопросов ЧГК (это чисто техническое дело, тут никакого ML нету)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-instrument",
   "metadata": {},
   "source": [
    "Для простоты будем считать что сложность турнира это средняя сложность вопросов в нем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-hypothetical",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_weights = {}\n",
    "for i, c in enumerate(encoder.get_feature_names()):\n",
    "    if c.startswith(\"x1_\"):\n",
    "        question_weights[c[3:]] = parameters[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_weights = question_answer_data.groupby(\"tournament_id\")[\"question\"].apply(lambda x: np.mean([question_weights[q] for q in x])).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_weights.reset_index()[\"tournament_id\"].apply(lambda x: tournaments[x][\"name\"]).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_weights.reset_index()[\"tournament_id\"].apply(lambda x: tournaments[x][\"name\"]).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-congo",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_weights = {}\n",
    "for i, c in enumerate(encoder.get_feature_names()):\n",
    "    if c.startswith(\"x0_\"):\n",
    "        player_weights[int(c[3:])] = parameters[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"players.pkl\", \"rb\") as fio:\n",
    "    players = pickle.load(fio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_players = sorted([(k, v) for k, v in player_weights.items()], reverse=True, key=lambda x: x[1])[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_players = {v for v, _ in top_20_players}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "[players[i][\"surname\"] + \" \" + players[i][\"name\"] + \" \" + players[i][\"patronymic\"] + \" \" + str(i) for i in top_20_players]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_data[question_answer_data[\"player\"].isin(top_20_players)].groupby(\"player\")[\"tournament_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-union",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
