{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "further-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vocational-banana",
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNKT_PATTERN = re.compile(r\"\\W+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "white-snowboard",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"data/AnnaKarenina.txt\", \"r\", encoding=\"utf8\") as fio:\n",
    "    corpus = fio.read()\n",
    "\n",
    "with open(\"data/WarAndPeace.txt\", \"r\", encoding=\"utf8\") as fio:\n",
    "    corpus += fio.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "painted-sacramento",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Annotation\\n\\n\\n«Анна Каренина», один из самых знаменитых романов Льва Толстого, начинается ставшей афоризмом фразой: «Все счастливые семьи похожи друг на друга, каждая несчастливая семья несчастлива по-'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "determined-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = PUNKT_PATTERN.sub(\" \", corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "continued-cornwall",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2385683"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "exciting-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = corpus[:-601]\n",
    "test1 = corpus[-601:]\n",
    "\n",
    "train2 = corpus[:-905]\n",
    "test2 = corpus[-905:]\n",
    "\n",
    "train3 = corpus[:-1903]\n",
    "test3 = corpus[-1903:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "voluntary-regression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Он уже наслаждался этим счастием когда вдруг являлся маленький Напoлеон с своим безучастным ограниченным и счастливым от несчастия других взглядом и начинались сомнения муки и только небо обещало успокоение К утру все мечтания смешались и слились в хаос и мрак беспамятства и забвения которые гораздо вероятнее по мнению самого Ларрея доктора Наполеона должны были разрешиться смертью чем выздоровлением C est un sujet nerveux et bilieux сказал Ларрей il n en rechappera pas Это человек нервный и желчный он не выздоровеет Князь Андрей в числе других безнадежных раненых был сдан на попечение жителей '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "future-salem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Те мечтания об отце жене сестре и будущем сыне и нежность которую он испытывал в ночь накануне сражения фигура маленького ничтожного Наполеона и над всем этим высокое небо составляли главное основание его горячечных представлений Тихая жизнь и спокойное семейное счастие в Лысых Горах представлялись ему Он уже наслаждался этим счастием когда вдруг являлся маленький Напoлеон с своим безучастным ограниченным и счастливым от несчастия других взглядом и начинались сомнения муки и только небо обещало успокоение К утру все мечтания смешались и слились в хаос и мрак беспамятства и забвения которые гораздо вероятнее по мнению самого Ларрея доктора Наполеона должны были разрешиться смертью чем выздоровлением C est un sujet nerveux et bilieux сказал Ларрей il n en rechappera pas Это человек нервный и желчный он не выздоровеет Князь Андрей в числе других безнадежных раненых был сдан на попечение жителей '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "promising-problem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Андрей не видал кто и как надел его опять но на груди его сверх мундира вдруг очутился образок на мелкой золотой цепочке Хорошо бы это было подумал князь Андрей взглянув на этот образок который с таким чувством и благоговением навесила на него сестра хорошо бы это было ежели бы всё было так ясно и просто как оно кажется княжне Марье Как хорошо бы было знать где искать помощи в этой жизни и чего ждать после нее там за гробом Как бы счастлив и спокоен я был ежели бы мог сказать теперь Господи помилуй меня Но кому я скажу это Или сила неопределенная непостижимая к которой я не только не могу обращаться но которой не могу выразить словами великое всё или ничего говорил он сам себе или это тот Бог который вот здесь зашит в этой ладонке княжной Марьей Ничего ничего нет верного кроме ничтожества всего того что мне понятно и величия чего то непонятного но важнейшего Носилки тронулись При каждом толчке он опять чувствовал невыносимую боль лихорадочное состояние усилилось и он начинал бредить Те мечтания об отце жене сестре и будущем сыне и нежность которую он испытывал в ночь накануне сражения фигура маленького ничтожного Наполеона и над всем этим высокое небо составляли главное основание его горячечных представлений Тихая жизнь и спокойное семейное счастие в Лысых Горах представлялись ему Он уже наслаждался этим счастием когда вдруг являлся маленький Напoлеон с своим безучастным ограниченным и счастливым от несчастия других взглядом и начинались сомнения муки и только небо обещало успокоение К утру все мечтания смешались и слились в хаос и мрак беспамятства и забвения которые гораздо вероятнее по мнению самого Ларрея доктора Наполеона должны были разрешиться смертью чем выздоровлением C est un sujet nerveux et bilieux сказал Ларрей il n en rechappera pas Это человек нервный и желчный он не выздоровеет Князь Андрей в числе других безнадежных раненых был сдан на попечение жителей '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "increasing-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(text):\n",
    "    chars = list(set(text))\n",
    "    codes = np.random.choice(np.arange(10000), size=len(chars), replace=False)\n",
    "    symbols = list(map(chr, codes))\n",
    "    mapping = dict(zip(chars, symbols))\n",
    "    encoded = [mapping[char] for char in text]\n",
    "    return \"\".join(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adjacent-dimension",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test1 = encode_text(test1)\n",
    "encoded_test2 = encode_text(test2)\n",
    "encoded_test3 = encode_text(test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-detective",
   "metadata": {},
   "source": [
    "# Часть 1\n",
    "\n",
    "Реализуйте базовый частотный метод по Шерлоку Холмсу:\n",
    "\n",
    "- подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
    "- возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
    "- расшифруйте их таким частотным методом.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fifty-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unigramm_mapping(encoded, train):\n",
    "    char_cnt = Counter(train)\n",
    "    encoded_cnt = Counter(encoded).most_common()\n",
    "    reverse_mapping = {}\n",
    "    for i, (char, _) in enumerate(char_cnt.most_common(len(encoded_cnt))):\n",
    "        reverse_mapping[encoded_cnt[i][0]] = char\n",
    "    return reverse_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daily-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_string(string, mapping):\n",
    "    decoded = [mapping[char] for char in string]\n",
    "    return \"\".join(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "domestic-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_mapping1 = get_unigramm_mapping(encoded_test1, train1)\n",
    "reverse_mapping2 = get_unigramm_mapping(encoded_test2, train2)\n",
    "reverse_mapping3 = get_unigramm_mapping(encoded_test3, train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cognitive-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_metric(y_true, y_pred):\n",
    "    return (np.array(list(y_true)) == np.array(list(y_pred))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "marine-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded1 = decode_string(encoded_test1, reverse_mapping1)\n",
    "decoded2 = decode_string(encoded_test2, reverse_mapping2)\n",
    "decoded3 = decode_string(encoded_test3, reverse_mapping3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "original-grain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Де ыйо ентснйднстм Лвир тпнтвиор яабдн кдлыб мксмстм рнсоезяиш Онжaсоае т ткаир чоьыпнтвеур аблнеипоееур и тпнтвсикур ав еотпнтвим длыбих кьбсмдар и енпиенситз тареоеим рыяи и васзяа еоча ачоiнса ытжаяаоеио К ывлы кто ропвнеим трофнситз и тсиситз к хнат и рлня чотжнрмвтвкн и ьнчкоеим яавалуо балньда коламвеоо жа реоеиП тнраба Снллом даявалн Онжасоаен дасйеу чуси лньлофивзтм тролвзП пор куьдалаксоеиор r гэщ юц эюИгщ цгeoгюn гщ uАsАгюn тяньнс Снллош Аs ц гц eгtТВННгeВ НВэ Мва посакоя еолкеуш и йоспеуш ае ео куьдалакоов Кемьз Яедлош к питсо длыбих чоьендойеух лнеоеух чус тдне ен жажопоеио йивосош '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "chronic-rendering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'По коулнаид ез елiо чоао тотлво и зяпяСок тмао и аочаетлг ьелевяэ еа итбмлмрнс р аеуг аньнаяао твнчоаид rиыявн кнсоагьеые аиулечаеые щнбесоеан и анп рток nлик рмтеьео аозе тетлнрсдси ыснраео етаернаио оые ыевдуоуамй бвоптлнрсоаиш Пийнд чижаг и тбеьешаео токошаео тунтлио р eмтмй Иевнй бвоптлнрсдситг окя oа ячо антснчпнстд nлик тунтлиок ьеыпн рпвяы дрсдстд кнсоагьиш щнбuсоеа т треик зожяунтламк еывнаиуоаамк и тунтлсирмк ел аотунтлид пвяыий ржысдпек и ануианситг текаоаид кяьи и лесгье аозе езоСнсе ятбеьеоаио s ялвя рто коулнаид ткоДнситг и тсиситг р йнет и квнь зотбнкдлтлрн и жнзроаид ьелевмо ыевнжпе роведлаоо бе каоаиэ тнкеые eнввод пеьлевн щнбесоеан песчам змси внжвоДилгтд тковлгэ уок рмжпеверсоаиок t хАВ юц АюТхВ цхНМхюЛ хВ ЯОaОхюЛ тьнжнс eнввош Оa ц хц НхlБКффхНК фКА mле уосероь аоврамш и чосуамш еа ао рмжпевероол sаджг cапвош р уитсо пвяыий зожанпочамй внаоамй змс тпна ан бебоуоаио чилосош '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "purple-hardwood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Оапвеч ае рнпил ксо н кик аипел еуо озмсы ао аи увгпн еуо тревш дгапнви рпвгу оьгснлтм обвижок аи делкоч жолосоч Лезоьке tовоцо бя хсо бяло зопгдил камжы Оапвеч ржулмагр аи хсос обвижок косовяч т сикнд ьгртсрод н блиуоуореанед аиретнли аи аеуо тетсви шовоцо бя хсо бяло ейелн бя ртa бяло сик мтао н звотсо кик оао кийестм камйае iивые щик шовоцо бя бяло жаисы упе нткисы зодоeн р хсоч йнжан н ьеуо йписы зотле аее сид жи увобод щик бя тьитслнр н тзокоеа м бял ейелн бя доу ткижисы сезевы rотзопн зоднлгч деам эо кодг м ткийг хсо Тлн тнли аеозвепелеааим аезотснйндим к косовоч м ае солыко ае доуг обвиeисытм ао косовоч ае доуг рявижнсы тлоридн релнкое ртa нлн аньеуо уоровнл оа тид тебе нлн хсо сос Моу косовяч рос жпеты жицнс р хсоч липоаке камйаоч iивыеч эньеуо аньеуо аес реваоуо кводе аньсойетсри ртеуо соуо ьсо дае зоамсао н релньнм ьеуо со аезоамсаоуо ао рийаечцеуо эотнлкн своаглнты Явн кийпод сольке оа озмсы ьгртсрорил аеряаотндгА болы лншовипоьаое тотсомане гтнлнлоты н оа аиьнаил бвепнсы Ие деьсианм об осЛе йеае тетсве н бгпгeед тяае н аейаотсы косовгА оа нтзясярил р аоьы аикиагае твийеанм lнугви дилеаыкоуо аньсойаоуо эизолеоаи н аип ртед хснд рятокое аебо тотсирлмлн улираое отаориане еуо уовмьеьаяш звептсирлеанч Иншим йнжаы н тзокочаое тедечаое тьитсне р Кятяш rовиш звептсирлмлнты едг Ба гйе аитлийпилтм хснд тьитснед коупи рпвгу мрлмлтм дилеаыкнч эизmлеоа т тронд бежгьитсаяд оувианьеааяд н тьитслнряд ос аетьитснм пвгунш ржулмпод н аиьнаилнты тодаеанм дгкн н солыко аебо обеeило гтзокоеане щ гсвг рте деьсианм тдецилнты н тлнлнты р шиот н двик бетзидмстсри н жибреанм косовяе уовижпо ревомсаее зо даеанА тидоуо Киввем поксови эизолеоаи полйая бялн вижвецнсытм тдевсыА ьед ряжповорлеанед c юфП ВН фВdюП НюСРюВo юП 1nunюВo ткижил Киввеч nu Н юН СюpЧsДДюСs Дsф Эсо ьелорек аевраяч н йельаяч оа ае ряжповореес щамжы Оапвеч р ьнтле пвгунш бежаипейаяш виаеаяш бял тпиа аи зозеьеане йнселеч '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "governing-deployment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.243\n",
      "2 0.207\n",
      "3 0.416\n"
     ]
    }
   ],
   "source": [
    "# как и ожидалось при увеличении размера закодированного сообщения качество растет\n",
    "\n",
    "for i, (original, decoded) in enumerate([(test1, decoded1), (test2, decoded2), (test3, decoded3)]):\n",
    "    print(i+1, round(decoding_metric(original, decoded), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-separate",
   "metadata": {},
   "source": [
    "# Часть 2\n",
    "\n",
    "Вряд ли в результате получилась такая уж хорошая расшифровка, разве что если вы брали в качестве тестовых данных целые рассказы. Но и Шерлок Холмс был не так уж прост: после буквы E, которая действительно выделяется частотой, дальше он анализировал уже конкретные слова и пытался угадать, какими они могли бы быть. Я не знаю, как запрограммировать такой интуитивный анализ, так что давайте просто сделаем следующий логический шаг:\n",
    "- подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
    "- проведите тестирование аналогично п.1, но при помощи биграмм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "invalid-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigrams(text):\n",
    "    return [text[i:i+2] for i in range(len(text) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "raised-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigramm_mapping(encoded, train):\n",
    "    char_cnt = Counter(train).most_common()\n",
    "    encoded_cnt = Counter(encoded).most_common()\n",
    "    \n",
    "    encoded_bigrams = Counter(get_bigrams(encoded)).most_common()\n",
    "    decoded_bigrams = Counter(get_bigrams(train)).most_common()\n",
    "    \n",
    "    mapping = {}\n",
    "    used = set()\n",
    "    to_decode = set()\n",
    "    \n",
    "    for enc, _ in encoded_bigrams:\n",
    "        if enc[0] in mapping and enc[1] in mapping:\n",
    "            continue\n",
    "        elif enc[0] in mapping:\n",
    "            mapped = mapping[enc[0]]\n",
    "            possible = [\n",
    "                dec for dec, _ in decoded_bigrams \n",
    "                if dec[0] == mapped and \n",
    "                dec[1] not in used\n",
    "            ]\n",
    "            if len(possible) > 1:\n",
    "                mapping[enc[1]] = possible[0][1]\n",
    "                used.add(possible[0][1])\n",
    "            else:\n",
    "                to_decode.add(enc[1])\n",
    "        elif enc[1] in mapping:\n",
    "            mapped = mapping[enc[1]]\n",
    "            possible = [\n",
    "                dec for dec, _ in decoded_bigrams\n",
    "                if dec[1] == mapped and \n",
    "                dec[0] not in used\n",
    "            ]\n",
    "            if len(possible) > 1:\n",
    "                mapping[enc[0]] = possible[0][0]\n",
    "                used.add(possible[0][0])\n",
    "            else:\n",
    "                to_decode.add(enc[0])\n",
    "        else:\n",
    "            possible = [\n",
    "                dec for dec, _ in decoded_bigrams \n",
    "                if dec[1] not in used and\n",
    "                dec[0] not in used\n",
    "            ]\n",
    "            mapping[enc[0]] = possible[0][0]\n",
    "            mapping[enc[1]] = possible[0][1]\n",
    "            \n",
    "    \n",
    "    encoded_cnt = [(var, cnt) for var, cnt in encoded_cnt if var in to_decode]\n",
    "    char_cnt = [(var, cnt) for var, cnt in char_cnt if var not in used]\n",
    "    for i, (enc, _) in enumerate(encoded_cnt):\n",
    "        mapping[enc] = char_cnt[i][0]\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "delayed-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_mapping1 = get_bigramm_mapping(encoded_test1, train1)\n",
    "reverse_mapping2 = get_bigramm_mapping(encoded_test2, train2)\n",
    "reverse_mapping3 = get_bigramm_mapping(encoded_test3, train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "irish-wheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded1 = decode_string(encoded_test1, reverse_mapping1)\n",
    "decoded2 = decode_string(encoded_test2, reverse_mapping2)\n",
    "decoded3 = decode_string(encoded_test3, reverse_mapping3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "engaged-medication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ь орПоо п опПупо нофи то ап и отозгчуповуерчонвоно нотпоо мз койпяВоог о о вг толоырап и стогчеп  ао  сто о ап ио встогио о ап и ноуерч довычонугто о па  по  мо гт о  нотрз о оигомзго олгоглоэпогор ягзго  оожориеров оотоаип  но тошпо  мо о о о  моводпг о отепзоло яптни ивпо оыплво  нозгигесоочгепыуговоегни оооягот о  Бо птгчгоюпееоноугзигепойпягоог поугоП солсо оепыеош им но тоеимБоаотовсыугегвоо  отоuобóхоъНоóъСбхоНбщnбъАобхоЛouoбъАо зпыпооюпееокоouоНобНощбasessбщeоseóоiигоаоогвозо оев ско оПооа ског о оовсыугегвооиож нымоr уеоковоа  оооуерч долоы пуоП сдоеп о сдолсоо уп о поягяоао  ооП иоооко'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "naughty-pricing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Но еогкьтоа ип икцо бото соскло о пужуiое свто о тобтискя рикилуы ит осшвквнь  н тигя тьрьтуто сльботоа Оодуль еь отяриди тогкибтиди чьши оить о тьж нсое Акое нвсирио топи сискьн а о д ьнтио истиньтоо оди дилагогтвй шложскьн отом Нойьа боютя о сширимтио соеомтио сгьскоо н звсвй Кильй шложскьн а ося оеу Ст убо тьс ьбжь са Акое сгьскоое риджь нжлуд ан а са еь отяром чьшo оит с сниое поюугьсктве идльтоготтве о сгьск онве ик тосгьскоа жлудой нюд ажие о тьготь ося сиетотоа еуро о ки яри топи ипоiь и усшириотоо В уклу нсо еогкьтоа сеофь ося о с о ося н йьис о ельр посшьеакскнь о юьпнотоа рикилво дильюжи нолиактоо ши етотоы сьеиди зьллоа жиркиль чьши оить жи бтв пв о льюлофокяса сеолкяы гое нвюжилин отоое Д эnх щe nщuэх eэaiэщu эх Лouoэщu срьюь  зьллом ou e эe aэristtэas tsn Тки го инор толнтвм о бо гтвм ит то нвюжилиноок Втаюя Мтжлом н гос о жлудой поютьжобтвй льтотвй пв  сжьт ть шишоготоо боко ом '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "outside-header",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Всмлоя со пемкр бто е бкб скмор о о огита со ск  луме о о нполй ьусмелк пмлу  одутерни овлкжоб ск ьорбоя жоротоя Погодбо Лолошо вы что выро гомуькр бсижа Всмлоя пж рисуп ск чтот овлкжоб ботолыя н ткбеь дупнтпоь е врк о опосеоь скпонерк ск со о нонтлк йолошо вы что выро охоре вы пнц выро ткб инсо е глонто бкб осо бкхотни бсихсо Оклао экб йолошо вы выро жскта  мо енбкта гоьоСе п чтоя хежсе е до о хмкта гонро соо ткь жк  ловоь экб вы ндкнтреп е нгобоос и выр охоре вы ьо  нбкжкта тогола Конгоме гоьеруя ьоси зо боьу и нбкху что Ире нерк соогломоросски согонтехеьки б ботолоя и со торабо со ьо у овлкСктани со ботолоя со ьо у пылкжета нропкье поребоо пнц ере седо о  ополер ос нкь ново ере что тот То  ботолыя пот жмона жкшет п чтоя ркмосбо бсихсоя Оклаоя зедо о седо о сот полсо о блоьо седтохонтпк пно о то о дто ьсо госитсо е поредеи до о то согоситсо о со пкхсояшо о зонербе тлосурена Мле бкхмоь тордбо ос огита дупнтпопкр сопысонеьую вора рейолкмодсоо нонтоисео унерерона е ос скдескр вломета До ьодтксеи ов отПо хосо нонтло е вумуСоь нысо е сохсонта ботолую ос енгытыпкр п сода скбксусо нлкхосеи Бе улк ькросабо о седтохсо о зкгорооск е скм пноь чтеь пынобоо сово нонткприре  ркпсоо онсопксео о о  олидодсый гломнткпросея Дейки хежса е нгобоясоо ноьоясоо ндкнтео п Аыный Колкй гломнткприрена оьу фс ухо скнркхмкрни чтеь ндкнтеоь бо мк пмлу  иприрни ькросабея зкгaроос н нпоеь вожудкнтсыь о лкседоссыь е ндкнтрепыь от сондкнтеи млу ей пж римоь е скдескрена ноьсосеи ьубе е торабо сово овоСкро унгобоосео э утлу пно ьодтксеи ньошкрена е нререна п йкон е ьлкб вонгкьитнтпк е жквпосеи ботолыо  олкжмо полоитсоо го ьсосею нкьо о Акллои мобтолк зкгорооск морхсы выре лкжлошетани ньолтаю доь пыжмолопросеоь Р Нne щЯ nщuНe ЯНsnНщu Нe ЭouoНщu нбкжкр Акллоя ou Я НЯ sНintrrНst rtn Что доропоб солпсыя е хордсыя ос со пыжмолопоот эсижа Всмлоя п денро млу ей вожскмохсый лксосый выр нмкс ск гогодосео хетороя '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "atlantic-advocate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.032\n",
      "2 0.223\n",
      "3 0.345\n"
     ]
    }
   ],
   "source": [
    "for i, (original, decoded) in enumerate([(test1, decoded1), (test2, decoded2), (test3, decoded3)]):\n",
    "    print(i+1, round(decoding_metric(original, decoded), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-radical",
   "metadata": {},
   "source": [
    "# Часть 3\n",
    "\n",
    "Но и это ещё не всё: биграммы скорее всего тоже далеко не всегда работают. Основная часть задания — в том, как можно их улучшить:\n",
    "- предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;\n",
    "- реализуйте и протестируйте его, убедитесь, что результаты улучшились.\n",
    "\n",
    "1. Возьмем случайный способ дешифровки\n",
    "2. Сделаем случайную перестановку 2х символов в дешифровке\n",
    "3. Посчитаем отношение вероятности встретить расшифрованный текст после перестановки к вероятности до перестановки\n",
    "4. Возьмем случайно число от 0 до 1 если оно меньше отношения:\n",
    "- да - оставляем\n",
    "- нет - отклоняем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "streaming-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_swap(decode_chars):\n",
    "    \n",
    "    indexes = np.random.choice(np.arange(len(decode_chars)), size=2, replace=False)\n",
    "    left_id, right_id = indexes\n",
    "    new_decode = decode_chars[:]\n",
    "    new_decode[left_id], new_decode[right_id] = new_decode[right_id], new_decode[left_id]\n",
    "    return new_decode\n",
    "\n",
    "\n",
    "def calc_proba(bigrams, guess, m, char_to_id):\n",
    "    total = 0\n",
    "    for bigram, cnt in bigrams:\n",
    "        row_id = char_to_id[guess[bigram[0]]]\n",
    "        col_id = char_to_id[guess[bigram[1]]]\n",
    "        total += cnt * m[row_id, col_id]\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "musical-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mcmc_mapping(encoded, train, n_epoches=20, n_iter=5000):\n",
    "    \n",
    "    encoded_bigrams = Counter(get_bigrams(encoded)).most_common()\n",
    "    decoded_bigrams = Counter(get_bigrams(train)).most_common()\n",
    "    \n",
    "    encoded_chars = list(set(encoded))\n",
    "    decoded_chars = list(set(train))\n",
    "\n",
    "    m = np.ones((len(decoded_chars), len(decoded_chars))) # заполним единичной встречаемостью чтобы избежать нулей\n",
    "    char_to_id = {char: i for i, char in enumerate(decoded_chars)}\n",
    "    for bigram, cnt in decoded_bigrams:\n",
    "        row_id = char_to_id[bigram[0]]\n",
    "        col_id = char_to_id[bigram[1]]\n",
    "        m[row_id, col_id] += cnt\n",
    "    \n",
    "    m /= m.sum()\n",
    "    m = np.log(m)\n",
    "    \n",
    "    probas = []\n",
    "    mappings = []\n",
    "    \n",
    "    for _ in range(n_epoches):\n",
    "        decoded_chars = list(set(train))\n",
    "        guess = dict(zip(encoded_chars, decoded_chars))\n",
    "        previous_proba = calc_proba(encoded_bigrams, guess, m, char_to_id)\n",
    "        for i in range(n_iter):\n",
    "            new_decoded_chars = random_swap(decoded_chars)\n",
    "            new_guess = dict(zip(encoded_chars, new_decoded_chars))\n",
    "            new_proba = calc_proba(encoded_bigrams, new_guess, m, char_to_id)\n",
    "            if new_proba > previous_proba:\n",
    "                decoded_chars = new_decoded_chars\n",
    "                previous_proba = new_proba\n",
    "                guess = new_guess\n",
    "            elif np.exp(new_proba - previous_proba) > np.random.rand():\n",
    "                decoded_chars = new_decoded_chars\n",
    "                previous_proba = new_proba\n",
    "                guess = new_guess\n",
    "        probas.append(previous_proba)\n",
    "        mappings.append(guess)\n",
    "    best_index = np.argmax(probas)\n",
    "    return mappings[best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "indirect-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_mapping1 = get_mcmc_mapping(encoded_test1, train1, 20, 5000)\n",
    "reverse_mapping2 = get_mcmc_mapping(encoded_test2, train2, 20, 5000)\n",
    "reverse_mapping3 = get_mcmc_mapping(encoded_test3, train3, 20, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "institutional-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded1 = decode_string(encoded_test1, reverse_mapping1)\n",
    "decoded2 = decode_string(encoded_test2, reverse_mapping2)\n",
    "decoded3 = decode_string(encoded_test3, reverse_mapping3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "little-birthday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.296\n",
      "2 0.389\n",
      "3 0.294\n"
     ]
    }
   ],
   "source": [
    "# качество для 5000 шагов выглядит не очень\n",
    "for i, (original, decoded) in enumerate([(test1, decoded1), (test2, decoded2), (test3, decoded3)]):\n",
    "    print(i+1, round(decoding_metric(original, decoded), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "widespread-communications",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_mapping1 = get_mcmc_mapping(encoded_test1, train1, 20, 50000)\n",
    "reverse_mapping2 = get_mcmc_mapping(encoded_test2, train2, 20, 50000)\n",
    "reverse_mapping3 = get_mcmc_mapping(encoded_test3, train3, 20, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aquatic-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded1 = decode_string(encoded_test1, reverse_mapping1)\n",
    "decoded2 = decode_string(encoded_test2, reverse_mapping2)\n",
    "decoded3 = decode_string(encoded_test3, reverse_mapping3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "split-consumption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.885\n",
      "2 0.944\n",
      "3 0.968\n"
     ]
    }
   ],
   "source": [
    "# однако при повышении количества шагов в 10 раз качество становится сильно лучше частотного метода\n",
    "for i, (original, decoded) in enumerate([(test1, decoded1), (test2, decoded2), (test3, decoded3)]):\n",
    "    print(i+1, round(decoding_metric(original, decoded), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "accomplished-resident",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Мн уже наслаждался этим счастием когда бдруг яблялся маленький Напшлеон с сбоим везучастным ограниченным и счастлибым от несчастия других бзглядом и начинались сомнения муки и только нево овецало успокоение А утру бсе мечтания смещались и слились б хаос и мрак веспамятстба и завбения которые гораздо бероятнее по мнению самого Даррея доктора Наполеона должны выли разрещиться смертью чем быздороблением И eis nt inves tempend es quruend сказал Даррей ur t et mezLallema lai Что челобек нербный и желчный он не быздоробеет Анязь Ондрей б числе других везнадежных раненых выл сдан на попечение жителей '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "annual-morocco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Не мечтания об отъе жене сестре и будуцем сыне и нежность которую он испытывал в ночь накануне сражения Лигура маленького ничтожного Каполеона и над всем этим высокое небо составляли главное основание его горячечных представлений Нихая жизнь и спокойное семейное счастие в Высых Порах представлялись ему Мн уже наслаждался этим счастием когда вдруг являлся маленький Капшлеон с своим безучастным ограниченным и счастливым от несчастия других взглядом и начинались сомнения муки и только небо обецало успокоение А утру все мечтания смещались и слились в хаос и мрак беспамятства и забвения которые гораздо вероятнее по мнению самого Варрея доктора Каполеона должны были разрещиться смертью чем выздоровлением Я eur ns under seipent er Тmoment сказал Варрей mo s es iechalleia lau Это человек нервный и желчный он не выздоровеет Анязь Ондрей в числе других безнадежных раненых был сдан на попечение жителей '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "received-plane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ондрей не видал кто и как надел его опять но на груди его сверх мундира вдруг очутился образок на мелкой золотой цепочке Ророшо бы это было подумал князь Ондрей взглянув на этот образок который с таким чувством и благоговением навесила на него сестра хорошо бы это было ежели бы всё было так ясно и просто как оно кажется княжне Дарье Вак хорошо бы было знать где искать помощи в этой жизни и чего ждать после нее там за гробом Вак бы счастлив и спокоен я был ежели бы мог сказать теперь Носподи помилуй меня Ко кому я скажу это Гли сила неопределенная непостижимая к которой я не только не могу обращаться но которой не могу выразить словами великое всё или ничего говорил он сам себе или это тот Бог который вот здесь зашит в этой ладонке княжной Дарьей Кичего ничего нет верного кроме ничтожества всего того что мне понятно и величия чего то непонятного но важнейшего Косилки тронулись При каждом толчке он опять чувствовал невыносимую боль лихорадочное состояние усилилось и он начинал бредить Ле мечтания об отце жене сестре и будущем сыне и нежность которую он испытывал в ночь накануне сражения фигура маленького ничтожного Каполеона и над всем этим высокое небо составляли главное основание его горячечных представлений Лихая жизнь и спокойное семейное счастие в Тысых Норах представлялись ему Ан уже наслаждался этим счастием когда вдруг являлся маленький КапЕлеон с своим безучастным ограниченным и счастливым от несчастия других взглядом и начинались сомнения муки и только небо обещало успокоение В утру все мечтания смешались и слились в хаос и мрак беспамятства и забвения которые гораздо вероятнее по мнению самого Таррея доктора Каполеона должны были разрешиться смертью чем выздоровлением И eus nt unoes telgenc es drirenc сказал Таррей ri t et lexpammela mau Сто человек нервный и желчный он не выздоровеет Внязь Ондрей в числе других безнадежных раненых был сдан на попечение жителей '"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-score",
   "metadata": {},
   "source": [
    "# Часть 4\n",
    "\n",
    "Расшифруйте сообщение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "experienced-shark",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded4 = \"დჳჵჂႨშႼႨშჂხჂჲდႨსႹႭჾႣჵისႼჰႨჂჵჂႨႲႹႧჲჂႨსႹႭჾႣჵისႼჰႨჲდႩჳჲႨჇႨႠჲႹქႹႨჳႹႹჱჶდსჂႽႨႩႹჲႹႭႼჰႨჵდქႩႹႨႲႭႹႧჂჲႣჲიႨ\" \\\n",
    "           \"ჳႩႹႭდდႨშჳდქႹႨშႼႨშჳდႨჳხდჵႣჵჂႨႲႭႣშჂჵისႹႨჂႨႲႹჵჇႧჂჲდႨჾႣႩჳჂჾႣჵისႼჰႨჱႣჵჵႨეႣႨႲႹჳჵდხსდდႨႧდჲშდႭჲႹდႨეႣხႣს\" \\\n",
    "           \"ჂდႨႩჇႭჳႣႨႾႹჲႽႨႩႹსდႧსႹႨႽႨსჂႧდქႹႨსდႨႹჱდჶႣნ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "precious-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_mapping = get_mcmc_mapping(encoded4, corpus, 50, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "center-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded4 = decode_string(encoded4, reverse_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "adjusted-colleague",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'если вы вимите норжальный или подти норжальный текст у этого соочшения который легко продитать скорее всего вы все смелали правильно и полудите жаксижальный чалл за послемнее детвертое замание курса ботя конедно я нидего не очешах'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "essential-microwave",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = \"если вы видите нормальный или почти нормальный текст у этого сообшения который легко \"\\\n",
    "           \"прочитать скорее всего вы все сделали правильно и получите максимальный балл за последнее \"\\\n",
    "           \"четвертое задание курса хотя конечно я ничего не обещаю\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fixed-crash",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9130434782608695"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoding_metric(expected, decoded4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-tuning",
   "metadata": {},
   "source": [
    "# Часть 5\n",
    "\n",
    "Бонус: а что если от биграмм перейти к триграммам (тройкам букв) или даже больше? Улучшатся ли результаты? Когда улучшатся, а когда нет? Чтобы ответить на этот вопрос эмпирически, уже может понадобиться погенерировать много тестовых перестановок и последить за метриками, глазами может быть и не видно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "exceptional-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_trigram_proba(trigrams, guess, m, char_to_id):\n",
    "    total = 0\n",
    "    for trigram, cnt in trigrams:\n",
    "        row_id = char_to_id[guess[trigram[0]]]\n",
    "        col_id = char_to_id[guess[trigram[1]]]\n",
    "        z_id = char_to_id[guess[trigram[2]]]\n",
    "        total += cnt * m[row_id, col_id, z_id]\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "incorrect-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trigrams(text):\n",
    "    return [text[i:i+3] for i in range(len(text) - 2)]\n",
    "\n",
    "\n",
    "def get_mcmc_trigram_mapping(encoded, train, n_epoches=20, n_iter=5000):\n",
    "    \n",
    "    encoded_trigrams = Counter(get_trigrams(encoded)).most_common()\n",
    "    decoded_trigrams = Counter(get_trigrams(train)).most_common()\n",
    "    \n",
    "    encoded_chars = list(set(encoded))\n",
    "    decoded_chars = list(set(train))\n",
    "\n",
    "    m = np.ones((len(decoded_chars), len(decoded_chars), len(decoded_chars))) # заполним единичной встречаемостью чтобы избежать нулей\n",
    "    char_to_id = {char: i for i, char in enumerate(decoded_chars)}\n",
    "    for bigram, cnt in decoded_trigrams:\n",
    "        row_id = char_to_id[bigram[0]]\n",
    "        col_id = char_to_id[bigram[1]]\n",
    "        z_id = char_to_id[bigram[2]]\n",
    "        m[row_id, col_id, z_id] += cnt\n",
    "    \n",
    "    m /= m.sum()\n",
    "    m = np.log(m)\n",
    "    \n",
    "    probas = []\n",
    "    mappings = []\n",
    "    \n",
    "    for _ in range(n_epoches):\n",
    "        decoded_chars = list(set(train))\n",
    "        guess = dict(zip(encoded_chars, decoded_chars))\n",
    "        previous_proba = calc_trigram_proba(encoded_trigrams, guess, m, char_to_id)\n",
    "        for i in range(n_iter):\n",
    "            new_decoded_chars = random_swap(decoded_chars)\n",
    "            new_guess = dict(zip(encoded_chars, new_decoded_chars))\n",
    "            new_proba = calc_trigram_proba(encoded_trigrams, new_guess, m, char_to_id)\n",
    "            if new_proba > previous_proba:\n",
    "                decoded_chars = new_decoded_chars\n",
    "                previous_proba = new_proba\n",
    "                guess = new_guess\n",
    "            elif np.exp(new_proba - previous_proba) > np.random.rand():\n",
    "                decoded_chars = new_decoded_chars\n",
    "                previous_proba = new_proba\n",
    "                guess = new_guess\n",
    "        probas.append(previous_proba)\n",
    "        mappings.append(guess)\n",
    "    best_index = np.argmax(probas)\n",
    "    return mappings[best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "competitive-vegetable",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_mapping1 = get_mcmc_trigram_mapping(encoded_test1, train1, 20, 5000)\n",
    "reverse_mapping2 = get_mcmc_trigram_mapping(encoded_test2, train2, 20, 5000)\n",
    "reverse_mapping3 = get_mcmc_trigram_mapping(encoded_test3, train3, 20, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "french-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded1 = decode_string(encoded_test1, reverse_mapping1)\n",
    "decoded2 = decode_string(encoded_test2, reverse_mapping2)\n",
    "decoded3 = decode_string(encoded_test3, reverse_mapping3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "compressed-cinema",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.483\n",
      "2 0.334\n",
      "3 0.335\n"
     ]
    }
   ],
   "source": [
    "for i, (original, decoded) in enumerate([(test1, decoded1), (test2, decoded2), (test3, decoded3)]):\n",
    "    print(i+1, round(decoding_metric(original, decoded), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "professional-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_mapping1 = get_mcmc_trigram_mapping(encoded_test1, train1, 20, 50000)\n",
    "reverse_mapping2 = get_mcmc_trigram_mapping(encoded_test2, train2, 20, 50000)\n",
    "reverse_mapping3 = get_mcmc_trigram_mapping(encoded_test3, train3, 20, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "frank-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded1 = decode_string(encoded_test1, reverse_mapping1)\n",
    "decoded2 = decode_string(encoded_test2, reverse_mapping2)\n",
    "decoded3 = decode_string(encoded_test3, reverse_mapping3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "tight-advocate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.963\n",
      "2 0.97\n",
      "3 0.977\n"
     ]
    }
   ],
   "source": [
    "for i, (original, decoded) in enumerate([(test1, decoded1), (test2, decoded2), (test3, decoded3)]):\n",
    "    print(i+1, round(decoding_metric(original, decoded), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "competent-transport",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_mapping = get_mcmc_trigram_mapping(encoded4, corpus, 50, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "approximate-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded4 = decode_string(encoded4, reverse_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "helpful-plastic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9782608695652174"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoding_metric(expected, decoded4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "broad-extent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'если вы видите нормальный или почти нормальный текст у Чтого сообжения который легко прочитать скорее всего вы все сделали правильно и получите максимальный балл за последнее четвертое задание курса Вотя конечно я ничего не обежащ'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-tracker",
   "metadata": {},
   "source": [
    "Триграммы дали лучшее качество на всех длиннах сообщений которые проверялись"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-simon",
   "metadata": {},
   "source": [
    "# Часть 6\n",
    "\n",
    "Бонус: какие вы можете придумать применения для этой модели? Пляшущие человечки ведь не так часто встречаются в жизни (хотя встречаются! и это самое потрясающее во всей этой истории, но об этом я расскажу потом).\n",
    "\n",
    "По сути модель похожа на поиск подграфа макимального веса в заданном графе, соотвественно может использоваться для:\n",
    "\n",
    "- Выявления связей в социальных сетей\n",
    "- Оптимизации маршрутов\n",
    "- В фармакалогии для поиска новых лекарств"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-champion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-diving",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
